<!DOCTYPE html>
<html lang="en">

<head>
            <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="Adams Rosales' personal blog on everything data, software, and working in the tech industry">
        <meta name="keywords" content="Data,Machine Learning,Data Science,Engineering,AI,Analytics,Big Data,Software">
        <meta name="author" content="Adams Rosales">

        <title>Deciphering Big Data</title>

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-DZPNKZL3NS"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-DZPNKZL3NS');
        </script>


        <!-- Bootstrap Core CSS -->
        <link href="/theme/css/bootstrap.min.css" rel="stylesheet">

        <!-- Custom CSS -->
        <link href="/theme/css/clean-blog.min.css" rel="stylesheet">

        <!-- Code highlight color scheme -->
            <link href="/theme/css/code_blocks/darkly.css" rel="stylesheet">

        <link rel="apple-touch-icon" sizes="180x180" href="extra/favicon/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="extra/favicon/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="extra/favicon/favicon-16x16.png">
        <link rel="icon" sizes="16x16 24x24 32x32 48x48 64x64" href="extra/favicon/favicon.ico">
        <link rel="manifest" href="extra/favicon/site.webmanifest">

        <!-- Custom Fonts -->
        <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
        <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->
        




        <meta name="tags" contents="Data Engineering" />


			<meta property="og:locale" content="en">
		<meta property="og:site_name" content="Deciphering Big Data">

	<meta property="og:type" content="article">
	<meta property="article:author" content="">
	<meta property="og:url" content="/scala-spark-hello-world.html">
	<meta property="og:title" content="Scala Spark Hello World">
	<meta property="og:description" content="">
	<meta property="og:image" content="//static/post15/header.jpg">
	<meta property="article:published_time" content="2021-03-27 00:00:00-07:00">
</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/">Deciphering Big Data</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
        <header class="intro-header" style="background-image: url('/static/post15/header.jpg');opacity: 0.9">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1>Scala Spark Hello World</h1>
                        <span class="meta">Posted by
                                <a href="https://www.linkedin.com/in/adamsr09/">Adams Rosales</a>
                             on Sat 27 March 2021
                        </span>
                        
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
    <!-- Post Content -->
    <article>
        <div class="section" id="motivation">
<h2>Motivation</h2>
<p>Spark is a hot skill these days! There are so many tutorials out there on it but I find that most of them miss the mark
on how you actually get started with a Spark project from scratch. Unless you've worked in a professional environment
with Spark pipelines written from scratch it's unlikely that you've been introduced to how to properly structure
a project, set up build dependencies, and write unit tests. In this post I go through a bare-bones SBT template as an
example of how to do just that.</p>
<p>I'm assuming you already have Scala, SBT, and Apache Spark installed. If not, you can follow <a class="reference external" href="https://docs.scala-lang.org/getting-started/sbt-track/getting-started-with-scala-and-sbt-on-the-command-line.html">the scala docs</a>
to install SBT and Scala and <a class="reference external" href="https://www.freecodecamp.org/news/installing-scala-and-apache-spark-on-mac-os-837ae57d283f/">this from freecodecamp</a> to
install Spark.</p>
</div>
<div class="section" id="create-sbt-project">
<h2>Create SBT Project</h2>
<p>We start by creating an empty directory, changing to it, and creating a hello world SBT project.</p>
<div class="highlight"><pre><span></span>&gt; mkdir scala-spark-hello-world
&gt; <span class="nb">cd</span> scala-spark-hello-world
&gt; sbt new scala/hello-world.g8
</pre></div>
<p>This creates the following directory structure in the scala-spark-hello-world directory.</p>
<img alt="Step 1 in creating a Spark Hello World project" src="/static/post15/post15_step1.png" style="width: 100%;" />
<p>We don't need the top level project or target directories so let's just delete them and cd into cala-spark-hello-world.</p>
<div class="highlight"><pre><span></span>&gt; rm -rf project target
&gt; <span class="nb">cd</span> cala-spark-hello-world
</pre></div>
<p>In cala-spark-hellow-world we are left with this structure.</p>
<img alt="Step 2 in creating a Spark Hello World project" src="/static/post15/post15_step2.png" style="width: 100%;" />
</div>
<div class="section" id="add-dependencies">
<h2>Add Dependencies</h2>
<p>The dependencies are specified in the build.sbt file. Spark needs to be listed as a dependency along with a compatible
Scala version to use according to the Spark version you choose. Here I'm using Spark 3.0.1, which requires Scala 2.12.
I'm also adding some additional dependencies like Scalactic and ScalaTest for unit testing and scopt for command line
parsing. We can also specify the assembly merge strategy for handling deduplication when building an uber/fat jar with
all of our dependencies.</p>
<p>We can go ahead and delete the existing build.sbt file and replace it with the code snippet below.</p>
<div class="highlight"><pre><span></span><span class="n">scalaVersion</span> <span class="o">:=</span> <span class="s">&quot;2.12.1&quot;</span>

<span class="n">name</span> <span class="o">:=</span> <span class="s">&quot;spark-hello-world&quot;</span>
<span class="n">organization</span> <span class="o">:=</span> <span class="s">&quot;ch.epfl.scala&quot;</span>
<span class="n">version</span> <span class="o">:=</span> <span class="s">&quot;1.0&quot;</span>

<span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-core&quot;</span> <span class="o">%</span> <span class="s">&quot;3.0.1&quot;</span><span class="o">,</span>
  <span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-sql&quot;</span> <span class="o">%</span> <span class="s">&quot;3.0.1&quot;</span>
<span class="o">)</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">&quot;com.github.scopt&quot;</span> <span class="o">%</span> <span class="s">&quot;scopt_native0.2_2.11&quot;</span> <span class="o">%</span> <span class="s">&quot;3.6.0&quot;</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">&quot;org.scalactic&quot;</span> <span class="o">%%</span> <span class="s">&quot;scalactic&quot;</span> <span class="o">%</span> <span class="s">&quot;3.2.5&quot;</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">&quot;org.scalatest&quot;</span> <span class="o">%%</span> <span class="s">&quot;scalatest&quot;</span> <span class="o">%</span> <span class="s">&quot;3.2.5&quot;</span> <span class="o">%</span> <span class="s">&quot;test&quot;</span>

<span class="n">assemblyMergeStrategy</span> <span class="n">in</span> <span class="n">assembly</span> <span class="o">:=</span> <span class="o">{</span>
  <span class="k">case</span> <span class="s">&quot;reference.conf&quot;</span> <span class="o">=&gt;</span> <span class="nc">MergeStrategy</span><span class="o">.</span><span class="n">concat</span>
  <span class="k">case</span> <span class="s">&quot;application.conf&quot;</span> <span class="o">=&gt;</span> <span class="nc">MergeStrategy</span><span class="o">.</span><span class="n">concat</span>
  <span class="k">case</span> <span class="nc">PathList</span><span class="o">(</span><span class="s">&quot;META-INF&quot;</span><span class="o">,</span> <span class="n">xs</span> <span class="o">@</span> <span class="k">_</span><span class="o">*)</span> <span class="o">=&gt;</span> <span class="nc">MergeStrategy</span><span class="o">.</span><span class="n">discard</span>
  <span class="k">case</span> <span class="k">_</span> <span class="o">=&gt;</span> <span class="nc">MergeStrategy</span><span class="o">.</span><span class="n">first</span>
<span class="o">}</span>
</pre></div>
<p>Next we have to add the <a class="reference external" href="https://github.com/sbt/sbt-assembly">assembly plugin</a> within the project directory in a
plugins.sbt file.</p>
<div class="highlight"><pre><span></span>&gt; <span class="nb">cd</span> project
&gt; touch plugins.sbt
</pre></div>
<p>Here is the one line to add to this plugins.sbt file.</p>
<div class="highlight"><pre><span></span><span class="n">addSbtPlugin</span><span class="o">(</span><span class="s">&quot;com.eed3si9n&quot;</span> <span class="o">%</span> <span class="s">&quot;sbt-assembly&quot;</span> <span class="o">%</span> <span class="s">&quot;0.15.0&quot;</span><span class="o">)</span>
</pre></div>
</div>
<div class="section" id="edit-src-packages">
<h2>Edit src Packages</h2>
<p>Now we're ready to start implementing the Spark logic. To do so let's reorganize the existing project a bit by creating
packages that will contain different components of our code and associated test packages for unit testing later on.</p>
<div class="highlight"><pre><span></span>&gt; <span class="nb">cd</span> src
<span class="c1"># Create test directory</span>
&gt; mkdir <span class="nb">test</span>
<span class="c1"># Create scala directory to mirror main</span>
&gt; mkdir test/scala
<span class="c1"># Remove existing Main file that&#39;s not needed</span>
&gt; rm main/scala/Main.scala
<span class="c1"># Create common package main and test directories</span>
&gt; mkdir main/scala/common test/scala/common
<span class="c1"># Create apps package in main and test directories</span>
&gt; mkdir main/scala/apps test/scala/apps
</pre></div>
<p>After all of that, the src directory will look like this.</p>
<img alt="Step 3 in creating a Spark Hello World project" src="/static/post15/post15_step3.png" style="width: 100%;" />
<p>The common package will hold components that are common across all of the codebase and the apps package will just hold
our simple Spark applications for now. This is just a bare-bones structure that can be edited to fit your use case.</p>
</div>
<div class="section" id="add-spark-session-wrappers">
<h2>Add Spark Session Wrappers</h2>
<p>When working with Spark you'll typically interact with the Spark session and context objects. Instead of instantiating
a bunch of these in different parts of the code base, you can define a single Spark session to be used across your
code. The way to do that naturally with Scala is with a trait that can be extended by objects and classes. Let's put
this wrapper in the common package.</p>
<div class="highlight"><pre><span></span><span class="k">package</span> <span class="nn">common</span>

<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">org.apache.spark.</span><span class="o">{</span><span class="nc">SparkConf</span><span class="o">,</span> <span class="nc">SparkContext</span><span class="o">}</span>

<span class="k">trait</span> <span class="nc">SparkWrapper</span> <span class="o">{</span>

  <span class="c1">// Set config</span>
  <span class="k">protected</span> <span class="k">val</span> <span class="n">sparkConf</span><span class="k">:</span> <span class="kt">SparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">()</span>
  <span class="k">protected</span> <span class="k">def</span> <span class="n">config</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">value</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="n">sparkConf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span>
  <span class="o">}</span>
  <span class="k">def</span> <span class="n">conf</span><span class="k">:</span> <span class="kt">SparkConf</span> <span class="o">=</span> <span class="k">this</span><span class="o">.</span><span class="n">sparkConf</span>

  <span class="k">def</span> <span class="n">appName</span><span class="k">:</span> <span class="kt">String</span>

  <span class="c1">// Build the spark session and retrieve spark context</span>
  <span class="k">protected</span> <span class="k">def</span> <span class="n">builder</span><span class="k">:</span> <span class="kt">SparkSession.Builder</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nc">SparkSession</span>
      <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
      <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="n">appName</span><span class="o">)</span>
      <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="n">conf</span><span class="o">)</span>
  <span class="o">}</span>
  <span class="k">def</span> <span class="n">spark</span><span class="k">:</span> <span class="kt">SparkSession</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
  <span class="k">def</span> <span class="n">sc</span><span class="k">:</span> <span class="kt">SparkContext</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="o">}</span>

<span class="k">trait</span> <span class="nc">SparkLocalWrapper</span> <span class="k">extends</span> <span class="nc">SparkWrapper</span><span class="o">{</span>
  <span class="k">override</span> <span class="k">def</span> <span class="n">builder</span><span class="k">:</span> <span class="kt">SparkSession.Builder</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">super</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
<p>The components that extend these SparkWrapper and SparkLocalWrapper traits will be able to use the single session (spark)
and context (sc) instances instead of defining their own. It also allows us to set the common configuration settings in
one place in the code base, which is generally good practice.</p>
<p>Notice also how we have two traits - SparkWrapper and SparkLocalWrapper. The former is meant to be used in cluster mode
when the application is run on something like EMR or a Hadoop cluster. The latter is used when running Spark on a local
machine like your computer. If you try to run the former on your computer you will typically run into an exception that
a host is not provided or something like that.</p>
<p>We will want to use the SparkLocalWrapper while running unit tests on our local machines. We will also want to turn off
some Spark logs and add some additional configurations so that Spark knows which local host/port to use and to only use
one partition. A good way to do this is with an additional wrapper in the test directory called SparkTestWrapper, which
extends from the SparkLocalWrapper available in main/scala/common.</p>
<div class="highlight"><pre><span></span><span class="k">package</span> <span class="nn">testutils</span>

<span class="k">import</span> <span class="nn">common.SparkLocalWrapper</span>

<span class="k">import</span> <span class="nn">org.apache.log4j.Level</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span>

<span class="k">object</span> <span class="nc">SparkTestWrapper</span> <span class="k">extends</span> <span class="nc">SparkLocalWrapper</span> <span class="o">{</span>
  <span class="o">{</span>
    <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">log4j</span><span class="o">.</span><span class="nc">Logger</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span><span class="s">&quot;org.apache.spark&quot;</span><span class="o">).</span><span class="n">setLevel</span><span class="o">(</span><span class="nc">Level</span><span class="o">.</span><span class="nc">WARN</span><span class="o">)</span>
    <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">log4j</span><span class="o">.</span><span class="nc">Logger</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span><span class="s">&quot;org.apache.hadoop.input.LineRecordReader&quot;</span><span class="o">).</span><span class="n">setLevel</span><span class="o">(</span><span class="nc">Level</span><span class="o">.</span><span class="nc">ERROR</span><span class="o">)</span>
    <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">log4j</span><span class="o">.</span><span class="nc">Logger</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span>
      <span class="s">&quot;org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter&quot;</span><span class="o">).</span><span class="n">setLevel</span><span class="o">(</span><span class="nc">Level</span><span class="o">.</span><span class="nc">ERROR</span><span class="o">)</span>
    <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">log4j</span><span class="o">.</span><span class="nc">Logger</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span><span class="s">&quot;org.apache.hadoop.output.FileOutputCommitter&quot;</span><span class="o">).</span><span class="n">setLevel</span><span class="o">(</span><span class="nc">Level</span><span class="o">.</span><span class="nc">ERROR</span><span class="o">)</span>
    <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">log4j</span><span class="o">.</span><span class="nc">Logger</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span>
      <span class="s">&quot;org.apache.hadoop.mapreduce.lib.input.LineRecordReader&quot;</span><span class="o">).</span><span class="n">setLevel</span><span class="o">(</span><span class="nc">Level</span><span class="o">.</span><span class="nc">ERROR</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">appName</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="s">&quot;SparkTestWrapper&quot;</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">conf</span><span class="k">:</span> <span class="kt">SparkConf</span> <span class="o">=</span> <span class="o">{</span>
    <span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.sql.shuffle.partitions&quot;</span><span class="o">,</span> <span class="s">&quot;1&quot;</span><span class="o">)</span>
    <span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.ui.enabled&quot;</span><span class="o">,</span> <span class="s">&quot;false&quot;</span><span class="o">)</span>
    <span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.driver.bindAddress&quot;</span><span class="o">,</span> <span class="s">&quot;127.0.0.1&quot;</span><span class="o">)</span>
    <span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.driver.host&quot;</span><span class="o">,</span> <span class="s">&quot;localhost&quot;</span><span class="o">)</span>
    <span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.sql.catalogImplementation&quot;</span><span class="o">,</span> <span class="s">&quot;in-memory&quot;</span><span class="o">)</span>
    <span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.driver.port&quot;</span><span class="o">,</span> <span class="s">&quot;8888&quot;</span><span class="o">)</span>
    <span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.sql.autoBroadcastJoinThreshold&quot;</span><span class="o">,</span> <span class="s">&quot;-1&quot;</span><span class="o">)</span>
    <span class="k">super</span><span class="o">.</span><span class="n">conf</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
<p>I have placed this in a separate test package called testutils (test/scala/testutils). The updated file tree looks like
this.</p>
<img alt="Step 4 in creating a Spark Hello World project" src="/static/post15/post15_step4.png" style="width: 100%;" />
</div>
<div class="section" id="add-spark-applications">
<h2>Add Spark Applications</h2>
<p>To add a Spark application we can create a new entry point in the apps package. Below is just a simple application to
count the words in a given block of text. It just parses the text using the scopt library and calls the countWords method
on it to perform the word counting. Notice how it extends the SparkWrapper from the common package and overrides the
appName. The spark object referenced here is defined in the SparkWrapper.</p>
<div class="highlight"><pre><span></span><span class="k">package</span> <span class="nn">apps</span>

<span class="k">import</span> <span class="nn">common.SparkWrapper</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>

<span class="k">object</span> <span class="nc">SparkWordCount</span> <span class="k">extends</span> <span class="nc">SparkWrapper</span> <span class="o">{</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">appName</span> <span class="o">=</span> <span class="s">&quot;Spark Word Count&quot;</span>

  <span class="k">case</span> <span class="k">class</span> <span class="nc">CliArgs</span><span class="o">(</span><span class="n">textToCount</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">)</span>

  <span class="k">def</span> <span class="n">parseCli</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">CliArgs</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">parser</span> <span class="o">=</span> <span class="k">new</span> <span class="n">scopt</span><span class="o">.</span><span class="nc">OptionParser</span><span class="o">[</span><span class="kt">CliArgs</span><span class="o">](</span><span class="s">&quot;SparkWordCountApp&quot;</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">head</span><span class="o">(</span><span class="s">&quot;Spark word count app&quot;</span><span class="o">)</span>
      <span class="n">opt</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&quot;textToCount&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">required</span><span class="o">()</span>
        <span class="o">.</span><span class="n">text</span><span class="o">(</span><span class="s">&quot;The text to count words with&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">action</span><span class="o">((</span><span class="n">param</span><span class="o">,</span> <span class="n">args</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">copy</span><span class="o">(</span><span class="n">textToCount</span> <span class="o">=</span> <span class="n">param</span><span class="o">))</span>
    <span class="o">}</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">parse</span><span class="o">(</span><span class="n">args</span><span class="o">,</span> <span class="nc">CliArgs</span><span class="o">()).</span><span class="n">getOrElse</span><span class="o">({</span>
      <span class="n">parser</span><span class="o">.</span><span class="n">showUsage</span>
      <span class="k">throw</span> <span class="k">new</span> <span class="nc">Exception</span><span class="o">(</span><span class="s">&quot;could not parse command&quot;</span><span class="o">)</span>
    <span class="o">})</span>
  <span class="o">}</span>

  <span class="cm">/**</span>
<span class="cm">   * Calculates the count of unique words in a collection of strings</span>
<span class="cm">   * @param text a sequence of individual strings to count words from</span>
<span class="cm">   * @return an RDD of word to count tuples</span>
<span class="cm">   */</span>
  <span class="k">def</span> <span class="n">countWords</span><span class="o">(</span><span class="n">text</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">String</span><span class="p">,</span> <span class="kt">Int</span><span class="o">)]</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="n">text</span><span class="o">)</span>
    <span class="n">lines</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">line</span> <span class="o">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="n">word</span> <span class="o">=&gt;</span> <span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
      <span class="o">.</span><span class="n">reduceByKey</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">cliArgs</span> <span class="o">=</span> <span class="n">parseCli</span><span class="o">(</span><span class="n">args</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">textToCount</span> <span class="o">=</span> <span class="n">cliArgs</span><span class="o">.</span><span class="n">textToCount</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">).</span><span class="n">toSeq</span>

    <span class="k">val</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">countWords</span><span class="o">(</span><span class="n">textToCount</span><span class="o">)</span>
    <span class="n">counts</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<div class="section" id="add-unit-tests">
<h2>Add Unit Tests</h2>
<p>To run unit tests on our Spark applications we can use the ScalaTest library. We'll just create corresponding files
in the test directory with the same name as the classes/objects defined in the main directory but suffixed with the word &quot;Test.&quot;
Below is a sample unit test for the countWords method in the SparkWordCount object defined above.</p>
<div class="highlight"><pre><span></span><span class="k">package</span> <span class="nn">apps</span>

<span class="k">import</span> <span class="nn">org.scalatest.funsuite.AnyFunSuite</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>

<span class="k">import</span> <span class="nn">testutils.SparkTestWrapper</span>

<span class="k">class</span> <span class="nc">SparkWordCountTest</span> <span class="k">extends</span> <span class="nc">AnyFunSuite</span> <span class="o">{</span>

  <span class="k">implicit</span> <span class="k">val</span> <span class="n">spark</span><span class="k">:</span> <span class="kt">SparkSession</span> <span class="o">=</span> <span class="nc">SparkTestWrapper</span><span class="o">.</span><span class="n">spark</span>

  <span class="n">test</span><span class="o">(</span><span class="s">&quot;testing that countWords can correctly generate a count of words from a block of text&quot;</span><span class="o">){</span>
    <span class="k">val</span> <span class="n">wordsToCount</span> <span class="o">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;some words to count&quot;</span><span class="o">,</span> <span class="s">&quot;some other words to count&quot;</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">countsOne</span> <span class="o">=</span> <span class="nc">SparkWordCount</span><span class="o">.</span><span class="n">countWords</span><span class="o">(</span><span class="n">wordsToCount</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">expectedCount</span> <span class="o">=</span> <span class="nc">Set</span><span class="o">((</span><span class="s">&quot;some&quot;</span><span class="o">,</span><span class="mi">2</span><span class="o">),</span> <span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">,</span><span class="mi">2</span><span class="o">),</span> <span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">,</span><span class="mi">2</span><span class="o">),</span> <span class="o">(</span><span class="s">&quot;other&quot;</span><span class="o">,</span><span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="s">&quot;to&quot;</span><span class="o">,</span><span class="mi">2</span><span class="o">))</span>
    <span class="n">assert</span><span class="o">(</span><span class="n">countsOne</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">toSet</span> <span class="o">==</span> <span class="n">expectedCount</span><span class="o">)</span>
  <span class="o">}</span>

<span class="o">}</span>
</pre></div>
<p>The final tree from the root project directory looks like this.</p>
<img alt="Step 5 in creating a Spark Hello World project" src="/static/post15/post15_step5.png" style="width: 100%;" />
</div>
<div class="section" id="build-it">
<h2>Build It</h2>
<p>To build our project we can simply run the SBT assembly process with the following command.</p>
<div class="highlight"><pre><span></span>&gt; sbt assembly
</pre></div>
<p>This should download the required dependencies, compile your code, and package all the necessary files into a fat or uber
jar that can be executed on your cluster of choice. This should also run your tests, which you will see in the terminal
as shown below.</p>
<img alt="Step 6 in creating a Spark Hello World project" src="/static/post15/post15_step6.png" style="width: 100%;" />
</div>
<div class="section" id="run-it">
<h2>Run It!</h2>
<p>To run your application you first need to find the uber jar created by sbt assembly. After running sbt assembly, you will
notice that a target directory was created in your root project directory. Travel there and into the scala-2.x subdirectory.</p>
<div class="highlight"><pre><span></span>&gt; <span class="nb">cd</span> target/scala-*
</pre></div>
<p>Here you will find an assembly jar as shown in the screenshot below.</p>
<img alt="Step 7 in creating a Spark Hello World project" src="/static/post15/post15_step7.png" style="width: 100%;" />
<p>You can then deploy this jar to wherever your cluster needs it to be. For example, if you're using EMR, you can deploy to
some S3 bucket. Then your spark-submit command can be something like the following. Notice the S3 path, which points to
the bucket I deployed my jar to.</p>
<div class="highlight"><pre><span></span>spark-submit --deploy-mode cluster --executor-memory 1g --class apps.SparkWordCount
s3://sparkjarsar/sparkflow-sparkapps-assembly-1.0.jar --textToCount <span class="s2">&quot;some words to count&quot;</span>
</pre></div>
<p>An example of all of this can be found in my <a class="reference external" href="https://github.com/adaros92/sparkflow-sparkapps">Github</a>. Happy coding!</p>
</div>

    </article>

    <hr>

            </div>
        </div>
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-2">
                    <!-- AddToAny BEGIN -->
                <div class="a2a_kit a2a_kit_size_32 a2a_default_style">
                    <a class="a2a_button_facebook"></a>
                    <a class="a2a_button_twitter"></a>
                    <a class="a2a_button_email"></a>
                    <a class="a2a_button_reddit"></a>
                    <a class="a2a_button_linkedin"></a>
                    <a class="a2a_button_evernote"></a>
                    <a class="a2a_dd" href="https://www.addtoany.com/share"></a>
                </div>
                <script async src="https://static.addtoany.com/menu/page.js"></script>
            </div>
        </div>
    </div>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <!-- AddToAny END -->
            <p class="copyright text-muted">Learn more about me at my <a href="https://www.linkedin.com/in/adamsr09/">LinkedIn</a> or <a href="https://github.com/adaros92">Github</a>.</p>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="/theme/js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="/theme/js/bootstrap.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="/theme/js/clean-blog.min.js"></script>

</body>

</html>