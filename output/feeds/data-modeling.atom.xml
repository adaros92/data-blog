<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Deciphering Big Data - Data Modeling</title><link href="https://decipheringbigdata.com/" rel="alternate"></link><link href="https://decipheringbigdata.com/feeds/data-modeling.atom.xml" rel="self"></link><id>https://decipheringbigdata.com/</id><updated>2020-12-13T00:00:00-08:00</updated><subtitle>Description of the site</subtitle><entry><title>Stars and Snowflakes</title><link href="https://decipheringbigdata.com/stars-and-snowflakes.html" rel="alternate"></link><published>2020-12-13T00:00:00-08:00</published><updated>2020-12-13T00:00:00-08:00</updated><author><name>Adams Rosales</name></author><id>tag:decipheringbigdata.com,2020-12-13:/stars-and-snowflakes.html</id><summary type="html">&lt;p class="first last"&gt;Structuring data in OLAP systems&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="requirements-in-an-olap-system"&gt;
&lt;h2&gt;Requirements in an OLAP System&lt;/h2&gt;
&lt;p&gt;In my previous &lt;a class="reference external" href="https://decipheringbigdata.com/be-normal.html"&gt;Be Normal&lt;/a&gt; post I mentioned that normalization is good
for OLTP but not so much for OLAP systems. The way you adapt data models for OLAP purposes is by de-normalizing tables in
a normalized data model. At a high level this process involves precomputing certain features and joining tables together
for our analyst customers.&lt;/p&gt;
&lt;p&gt;Analysts typically need to answer complex business questions dealing with certain &amp;quot;facts&amp;quot; about a business. For example,
what do revenues look like over time? What category of product sells the best during sale periods? Which apps are the
top performing as measured by daily active users? With a highly normalized database, the analysts would have to write
complex queries to join many different tables together and aggregate up individual records to produce the summarized
figures they need in order to answer these questions.&lt;/p&gt;
&lt;p&gt;Here I discuss how we may go about making this process easier by designing an OLAP data model with the help of two buzz
phrases in the data modeling community: star and snowflake schemas.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="star-schemas"&gt;
&lt;h2&gt;Star Schemas&lt;/h2&gt;
&lt;p&gt;The basic premise of a star schema is to organize your data such that you store your key business measures that analysts
care about in one or many fact tables. How granular you go with these measures is really up to the needs of the business
and what types of questions we want to answer with the data.&lt;/p&gt;
&lt;p&gt;These fact tables will then have &lt;a class="reference external" href="https://www.techopedia.com/definition/7272/foreign-keyl"&gt;foreign keys&lt;/a&gt; to other
tables in the database that describe the numerical facts stored in the fact tables. These types of tables are called
dimensions and commonly deal with locations, time, products, organizations, and people.&lt;/p&gt;
&lt;p&gt;This gives us a central denormalized location where the crucial measures are stored so that we don't have to join a
bunch of system tables together to derive those measures and some lookup tables that we can easily join to segment the
data depending on the task at hand.&lt;/p&gt;
&lt;p&gt;Take the following normalized set of tables from the &lt;a class="reference external" href="https://decipheringbigdata.com/be-normal.html"&gt;previous post&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Complex OLTP diagram" src="/static/post4/post4_complexdiagram.jpg" style="width: 90%;" /&gt;
&lt;p&gt;Some of the business questions we may want to ask about these data are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;How much sales revenue was brought in over some time period by product category?&lt;/li&gt;
&lt;li&gt;How many orders were processed by store?&lt;/li&gt;
&lt;li&gt;How many units were shipped by location?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The facts here are most likely to be units, orders, and dollar revenue and we should be able to segment these by the
different groups of attributes shown - sales staff, stores, customer locations, and product categories. Here is
one option for a star schema to capture these requirements.&lt;/p&gt;
&lt;img alt="Sample star schema" src="/static/post5/post5_star.jpg" style="width: 100%;" /&gt;
&lt;p&gt;We have pre-aggregated the measures we care about and stored them with references to all of the descriptive attributes
to segment by in one fact_orders table. The dimensions are other denormalized tables that combine all characteristics
of the specific subjects in one table per subject. This simplifies the OLTP model substantially and makes it a lot
easier to answer the business questions above.&lt;/p&gt;
&lt;p&gt;For example, here is the SQL to answer how much sales revenue was brought in over some time period by product category.
${PERIOD_START} and ${PERIOD_END} are user inputs for the time period in question.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;FO&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ORDER_DATE&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DP&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PRODUCT_CATEGORY&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;SUM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;FO&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ORDER_AMOUNT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;TOTAL_ORDER_AMOUNT&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;FACT_ORDERS&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;FO&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;JOIN&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;DIM_PRODUCT&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;ON&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;FO&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PRODUCT_ID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DP&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PRODUCT_ID&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;WHERE&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="n"&gt;FO&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ORDER_DATE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;BETWEEN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;${&lt;/span&gt;&lt;span class="n"&gt;PERIOD_START&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;AND&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;${&lt;/span&gt;&lt;span class="n"&gt;PERIOD_END&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;GROUP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;BY&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;FO&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ORDER_DATE&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DP&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PRODUCT_CATEGORY&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Compare that to the logic required to get the same answer but from the normalized OLTP data model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;SOH&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OrderDate&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ORDER_DATE&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PC&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PRODUCT_CATEGORY&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;SUM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SOD&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OrderQty&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SOD&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;UnitPrice&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;TOTAL_ORDER_AMOUNT&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;SalesOrderDetail&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SOD&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;JOIN&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;SalesOrderHeader&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SOH&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;ON&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SOD&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SalesOrderID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SOH&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SalesOrderID&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;JOIN&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Product&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;ON&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SOD&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProductID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProductID&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;JOIN&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;ProductSubcategory&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PSC&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;ON&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProductSubcategoryID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PSC&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProductSubcategoryID&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;JOIN&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;ProductCategory&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PC&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;ON&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PSC&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProductCategoryID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PC&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProductCategoryID&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;WHERE&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="n"&gt;SOH&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OrderDate&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;BETWEEN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;${&lt;/span&gt;&lt;span class="n"&gt;PERIOD_START&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;AND&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;${&lt;/span&gt;&lt;span class="n"&gt;PERIOD_END&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;GROUP&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;BY&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;SOH&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OrderDate&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PC&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's a lot of joins!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="snowflake-schemas"&gt;
&lt;h2&gt;Snowflake Schemas&lt;/h2&gt;
&lt;p&gt;The premise of snowflake schemas is essentially the same as star schemas but instead of denormalizing dimensions into
as few tables per subject as possible we instead normalize the dimensions. This is done to optimize storage space by
avoiding redundant information and make updates more efficient.&lt;/p&gt;
&lt;p&gt;In some cases your facts and dimensions may share many-to-many relationships. Storing the same attributes repeatedly for
each fact_key and dim_key combination can take up a lot of unnecessary space. It's preferred in these cases to create a
separate table that just stores the relationship between fact_key and dim_key without any additional attributes to use as
a bridge table from the fact to the dim. Other times you may not need some dimension attributes as often as others
so you may choose to store them separately in a different table so that queries are more efficient (in row-based databases).&lt;/p&gt;
&lt;p&gt;There's really no rule about how much normalization there should be. It's often dictated by the systems the data are
sourced from, the ETL processes in place, personal/team preference, what other data are stored alongside the schemas,
where the data are stored in, etc. What is fairly constant though is that snowflake schemas will most often lead to
worse query performance due to the extra joins that need to happen between fact and dim tables to answer business
questions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="are-these-modeling-techniques-used-in-practice"&gt;
&lt;h2&gt;Are These Modeling Techniques Used In Practice?&lt;/h2&gt;
&lt;p&gt;It depends. I have found that interviewers for data engineering positions focus a lot on star schema modeling but I have not
actually come across true star schemas that often on the job. I have seen relics of star schemas with dim tables here and
there but it always seems like people just abandon the approach and data tend to merge together into a set of core tables
combining both dims and facts.&lt;/p&gt;
&lt;p&gt;Part of the reason why is that nowadays companies are moving away from traditional data warehousing techniques and
storing the data in key-value/object stores like AWS S3. With tools like Spark on EMR and Presto/Athena, data doesn't
really need to be stored in any data warehouse for analysts to derive value from it. They can also take on different
types of structure where the data are completely denormalized into single datasets or split together in ways that don't
really adhere to any sort of schema. The types of tools used to consume the data offer a lot more flexibility in how
the data are read and manipulated than traditional data warehousing solutions.&lt;/p&gt;
&lt;p&gt;When data are stored in data warehouses like Redshift, they're typically stored in single tables that combine both facts
and dimensions. This is mainly because with efficient compute behind the scenes (either Redshift or Spark on data stored
in S3), it's easy to recompute large amounts of data (up to hundreds of terabytes) in a relatively short period of time.
That is if a dimension changes, the dataset owners can easily backfill that dimension into the one table that also has
facts within a matter of hours or days.&lt;/p&gt;
&lt;p&gt;I think these techniques are still worth understanding as logical data models, but they're not requirements
when physically storing the data.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Data Modeling"></category><category term="Data Modeling"></category></entry><entry><title>Be Normal</title><link href="https://decipheringbigdata.com/be-normal.html" rel="alternate"></link><published>2020-12-12T00:00:00-08:00</published><updated>2020-12-12T00:00:00-08:00</updated><author><name>Adams Rosales</name></author><id>tag:decipheringbigdata.com,2020-12-12:/be-normal.html</id><summary type="html">&lt;p class="first last"&gt;The normal forms of OLTP data modeling&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="what-is-data-normalization"&gt;
&lt;h2&gt;What is Data Normalization?&lt;/h2&gt;
&lt;p&gt;Normalization is a fancy term to describe the process of organizing data into relations or tables to remove redundancy
through decomposition.&lt;/p&gt;
&lt;p&gt;There are 5 different forms of normalization:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;First Normal Form&lt;/li&gt;
&lt;li&gt;Second Normal Form&lt;/li&gt;
&lt;li&gt;Third Normal Form&lt;/li&gt;
&lt;li&gt;Boyce and Codd Normal Form&lt;/li&gt;
&lt;li&gt;Fourth Normal Form&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As we go down this list data becomes less redundant and the more tables we end up with in our database. I'll walk
through concrete examples of these different forms below!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="a-world-without-normalization"&gt;
&lt;h2&gt;A World Without Normalization&lt;/h2&gt;
&lt;p&gt;First let's take a look at what lack of data normalization means. It helps to picture a giant spreadsheet that collects
all kinds of data about some subject. Let's say someone in your neighborhood keeps a spreadsheet of every single person
that lives in the neighborhood. It contains the relationships between neighbors in separate columns, the colors of the
houses, how many cars each house has, when deliveries and public services like trash collection pass by each house, etc.&lt;/p&gt;
&lt;p&gt;It looks something like this (shout out to &lt;a class="reference external" href="https://www.behindthename.com/random/"&gt;https://www.behindthename.com/random/&lt;/a&gt;).&lt;/p&gt;
&lt;img alt="Creepy neighbordhood spreadsheet" src="/static/post4/post4_normalization1.jpg" style="width: 100%;" /&gt;
&lt;p&gt;If keeping a creepy list did not raise any red flags before, this atrocity of a data structure should. It's not difficult to
imagine how difficult it would be to maintain data in such a list as it grows. Updates would be a pain! For example,
if a neighbor paints their house you would need to update each household member's record in this list, not just
a single house record. If Alf has a baby, you will need to add a family_3 column to record the relationship between the
existing 3 members and the new addition to the family. This affects all records in the table. Same thing if someone gets
a new car or the garbage collection routes change.&lt;/p&gt;
&lt;p&gt;So let's say your creepy neighbor wants to do better. What can they do?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="first-normal-form"&gt;
&lt;h2&gt;First Normal Form&lt;/h2&gt;
&lt;p&gt;First normal form refers to data models that have only atomic values in each column and where no table has repeating
groups. Atomic values are simply those that can't be broken down into many values. Fortunately all of the values in
this spreadsheet are atomic. If we had a column called cars and in that column we had a record like
Toyota Camry, Toyota Camry, Toyota Corolla then this value would need to be broken down so that each value is stored
in its own record.&lt;/p&gt;
&lt;p&gt;What we do have here though are repeating groups. This refers to groups of values that can repeat for any one of the
primary keys in the tables. In this case, values that can repeat for each neighbor stored in the spreadsheet. Those
groups are the car, family, and friend columns.&lt;/p&gt;
&lt;p&gt;The solution to get rid of these repeating groups is to split the one table into 3 individual tables - neighbors,
vehicles, and relationships.&lt;/p&gt;
&lt;img alt="First normal form example" src="/static/post4/post4_fnf.jpg" style="width: 100%;" /&gt;
&lt;p&gt;The vehicles table will have the name of each person and a vehicle in their household. It's easier to update the vehicles
in each household now because we don't need to amend all records in the table by changing a column. We can simply amend,
delete, or add rows in the vehicles table. The same is true for relationships between neighbors. To add new ones we can
simply append rows to the relationships table.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="second-normal-form"&gt;
&lt;h2&gt;Second Normal Form&lt;/h2&gt;
&lt;p&gt;Second normal form dictates that &amp;quot;all non-key attributes should be functionality dependent on the primary key.&amp;quot; What
this means in plain English is that each table should contain only information about one topic and all attributes in
that table should serve to describe the topic and nothing else.&lt;/p&gt;
&lt;p&gt;For example, in our first normal form model, the color of the house and the garbage routes are stored with the neighbors
table. The primary key of that table is the neighbor's name. Neither the house color nor the garbage route depend on
each neighbor. They instead depend solely on the house where the neighbors live in. Each house is uniquely identified
by an address in our data so each of these attributes should be stored in its own table as shown below.&lt;/p&gt;
&lt;img alt="Second normal form example" src="/static/post4/post4_snf.jpg" style="width: 100%;" /&gt;
&lt;p&gt;The advantage of this data model is that we remove the additional redundancy of having attributes related to the address
in the neighbors table where addresses can be repeated for each neighbor that lives in the same house as other neighbors.
For example, if we wanted to update the color of the house at 12234 NE 20th ST, we would only need to do it once in the
location_attributes table instead of 3 times in the neighbors table.&lt;/p&gt;
&lt;p&gt;It also means that if we delete any records from the neighbors table because people move out of the neighborhood, we
will still preserve all of the information related to the houses at the locations where they used to live.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="third-normal-form"&gt;
&lt;h2&gt;Third Normal Form&lt;/h2&gt;
&lt;p&gt;Tables should contain columns that are non-transitively dependent on the primary key.&lt;/p&gt;
&lt;img alt="Confused Marky Mark" src="https://media.giphy.com/media/zjQrmdlR9ZCM/giphy.gif" style="width: 60%;" /&gt;
&lt;p&gt;This one sounds complicated but it actually just means that we shouldn't store columns that depend on the primary key
of a table AND on other columns in that table. For example, our garbage_collection table has a column for the route
number and for the day when the garbage truck swings by at an address. Garbage route depends on the address and the day
of collection depends on the garbage route so a transitive dependency exists.&lt;/p&gt;
&lt;p&gt;The reason why we don't want these types of dependencies in our tables is because updates have to change multiple
attributes in a table when one attribute in the transitive dependency is updated, which can lead to inconsistencies.
For example, if we assign a different route to an address and that route runs on a different date then we also need to
update the date of collection for the address. We need to make sure to update both or else our data will be wrong.&lt;/p&gt;
&lt;p&gt;To fix it we can just add an additional table that stores the relationship between route and collection day.&lt;/p&gt;
&lt;img alt="Third normal form example" src="/static/post4/post4_tnf.jpg" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="boyce-and-codd-normal-form"&gt;
&lt;h2&gt;Boyce and Codd Normal Form&lt;/h2&gt;
&lt;p&gt;This normal form adds a minor restriction to the third normal form - attributes should depend only on a super key (a
column or collection of columns that uniquely identify records in a table).&lt;/p&gt;
&lt;p&gt;Our data model above is both in 3NF and BCNF but suppose instead that we also stored the garbage collection crew number
in the garbage_routes table. The individual crew would determine the collection_day based on when they work in the week
so collection_day would depend on the crew number. However, crew number would not be a super key because one crew can
service multiple routes (crew number would not uniquely identify records in this table). This scenario would satisfy
3NF constraints but not BCNF constraints.&lt;/p&gt;
&lt;p&gt;We could fix a scenario like this by splitting the garbage_routes table into two, one storing the relationship between
route and crew and another storing the relationship between crew and collection_day.&lt;/p&gt;
&lt;img alt="BCNF example" src="/static/post4/post4_bcnf.jpg" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="fourth-normal-form"&gt;
&lt;h2&gt;Fourth Normal Form&lt;/h2&gt;
&lt;p&gt;Finally, the fourth normal form requires us to avoid multi-valued dependencies in tables. This means that for any
dependency A -&amp;gt; B in a table, if multiple values of B exist for any single value of A and there are more than 2 columns
in that table then there is a multi-valued dependency violating the 4NF.&lt;/p&gt;
&lt;p&gt;Our BCNF data model above also satisfies 4NF but what if a single crew had multiple collection days and we also stored
the truck_id of each crew in the crew_collection_days table. Truck_id and collection_day here are independent of each
other so BCNF is satisfied but this would be a multi-valued dependency because the key crew_number can have multiple
collection days and can drive one or more trucks&lt;/p&gt;
&lt;p&gt;We can further normalize this by splitting crew_collection_days into two tables, one that maintain the one to many
relationship between crew_number and collection_day and another the one to many relationship between crew_number and
truck_id.&lt;/p&gt;
&lt;img alt="Fourth normal form example" src="/static/post4/post4_4nf.jpg" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="normalize-all-the-tables"&gt;
&lt;h2&gt;Normalize All The Tables?&lt;/h2&gt;
&lt;p&gt;Normalization kicks ass, right? Well, not always. There are cases where we may want to do the opposite of normalizing
or as they say in the biz, &amp;quot;de-normalize.&amp;quot;&lt;/p&gt;
&lt;p&gt;Normalization works well in OLTP databases where tables are strongly tied to engineering systems that update them. These
are your point-of-sale, online checkout, messaging applications, etc. which are organized into individual
objects that maintain state and functionality for very specific components of the broader systems. The individual
objects may not be aware of other objects' state and so can only update the data for the specific table that backs
the one component. For example, a post class that's part of a forum web application updating a post table which just
contains information about individual posts on the forum and nothing else.&lt;/p&gt;
&lt;p&gt;For OLAP workloads that seek to answer overarching business questions, normalized databases can actually be
a hindrance. This is because to answer the types of analytical questions typically asked in these settings, an analyst
would need to first understand how all of the tables in a complex model like the one shown below fit together and then
write a massive query to join all of the tables together. Such a query would be inefficient and error-prone.&lt;/p&gt;
&lt;img alt="Complex OLTP diagram" src="/static/post4/post4_complexdiagram.jpg" style="width: 90%;" /&gt;
&lt;p&gt;For example, say an analyst were asked to produce a summary of total quantity ordered for product categories that were
under special offer during some time range. The analyst would need to join the SalesOrderHeader, SalesOrderDetail,
SpecialOfferProduct, SpecialOffer, Product, ProductSubcategory, and ProductCategory tables together to produce an
answer. Not a fun exercise!&lt;/p&gt;
&lt;p&gt;In these cases, pre-joining tables together or &amp;quot;de-normalizing&amp;quot; makes sense. We're willing to break normalization rules
and introduce some redundancy to our data models in order to make analytical queries more efficient and make the lives
of our analytics customers easier. This is where star and snowflake schemas come in handy but that's a different topic
for another day!&lt;/p&gt;
&lt;/div&gt;
</content><category term="Data Modeling"></category><category term="Data Modeling"></category></entry></feed>